import os
import tensorflow as tf
import ml_collections
from jaxrl_m.agents.continuous.cql import (
    get_default_config as get_continuous_cql_config,
)
from jaxrl_m.agents.continuous.diffusion_q_learning import (
    get_default_config as get_diffusion_q_learning_config,
)

SAVE_DIR_PREFIX = os.environ.get("SAVE_DIR_PREFIX", "./")


def get_config(config_string):
    possible_structures = {
        "diffusion_cql": ml_collections.ConfigDict(
            dict(
                agent="diffusion_cql",
                batch_size=256,
                save_dir=tf.io.gfile.join(SAVE_DIR_PREFIX, "results"),
                seed=0,
                eval_interval=500,
                validation_interval=100,
                save_interval=500,
                log_interval=10,
                deterministic_eval=False,
                num_eval_episodes=50,
                num_episodes_per_video=5,
                num_episodes_per_row=5,
                save_video=False,
                agent_kwargs=get_continuous_cql_config(
                    updates=dict(
                        policy_kwargs=dict(
                            tanh_squash_distribution=True,
                            std_parameterization="uniform",
                        ),
                        discount=0.99,
                        batch_size=256,
                        distributional_critic=True,
                        distributional_critic_kwargs=dict(
                            q_min=-100.0,
                            q_max=0.0,
                            num_bins=128,
                        ),
                        critic_network_type="mlp",
                        critic_kwargs=dict(
                            kernel_init_type="orthogonal",
                            kernel_init_params=dict(
                                scale=1e-2,
                            ),
                        ),
                        critic_network_kwargs=dict(
                            hidden_dims=(256, 256),
                            activate_final=True,
                            kernel_scale_final=1e-2,
                            use_feature_normalization=False,
                            use_layer_norm=True,
                        ),
                        policy_network_kwargs={
                            "hidden_dims": [256, 256],
                            "activate_final": True,
                            "use_layer_norm": False,
                            "use_group_norm": False,
                            "kernel_scale_final": 1e-2,
                        },
                        actor_optimizer_kwargs=dict(
                            learning_rate=1e-4,
                            warmup_steps=0,
                        ),
                        critic_optimizer_kwargs={
                            "learning_rate": 3e-4,
                            "warmup_steps": 0,
                            "weight_decay": 0.0,
                        },
                        temperature_optimizer_kwargs={
                            "learning_rate": 1e-4,
                        },
                        cql_importance_sample=False,
                        cql_n_actions=10,
                        num_ddpm_actions=32,
                        num_actions_to_keep_for_q_diffusion=10,
                        q_diffusion_num_steps=10,
                        q_diffusion_num_steps_for_cql=-1,  # use q_diffusion_num_steps
                        q_diffusion_step_size=3e-4,
                        q_diffusion_optimize_critic_ensemble_min=False,
                        q_diffusion_use_adam=False,
                        q_diffusion_adam_kwargs=dict(
                            b1=0.9,
                            b2=0.999,
                            clip_grad_norm=-1.0,
                        ),
                        q_diffusion_half_step_size_on_overshooting=False,
                        q_diffusion_overshooting_factor=0.5,
                        train_gaussian_policy=False,
                        use_gaussian_policy_for_critic_training=False,
                        always_use_argmax_for_q_diffusion=True,
                        use_calql=True,
                        use_calql_on_random_actions=False,
                        autotune_entropy=False,
                        cql_autotune_alpha=False,
                        use_target_critic_for_q_diffusion_steps=False,
                        use_dataset_actions_for_cql_regularization=False,
                        critic_ensemble_size=10,
                        critic_subsample_size=2,
                        policy_optimizes_ensemble_mean=True,
                        drq_padding=0,
                    ),
                ),
                image_observations=False,
                goal_conditioned=False,
                bound_q_targets=False,
                improve_ddpm_actions_with_global_search=False,
                ddpm_agent_path="",
                ddpm_agent_kwargs=dict(
                    batch_size=256,
                    score_network_kwargs=dict(
                        time_dim=128,
                        num_blocks=3,
                        dropout_rate=0.1,
                        hidden_dim=256,
                        use_layer_norm=True,
                    ),
                    use_proprio=False,
                    beta_schedule="cosine",
                    diffusion_steps=5,
                    action_samples=64,
                    repeat_last_step=0,
                    learning_rate=3e-4,
                    warmup_steps=2000,
                    actor_decay_steps=int(3e6),
                    image_observations=False,
                ),
            )
        ),
        "ddpm": ml_collections.ConfigDict(
            dict(
                agent="ddpm_bc",
                batch_size=256,
                save_dir=tf.io.gfile.join(SAVE_DIR_PREFIX, "results"),
                seed=0,
                eval_interval=500,
                validation_interval=100,
                save_interval=1000,
                log_interval=10,
                deterministic_eval=False,
                num_eval_episodes=50,
                num_episodes_per_video=5,
                num_episodes_per_row=5,
                save_video=False,
                image_observations=False,
                goal_conditioned=False,
                agent_kwargs=dict(
                    score_network_kwargs=dict(
                        time_dim=128,
                        num_blocks=3,
                        dropout_rate=0.1,
                        hidden_dim=256,
                        use_layer_norm=True,
                    ),
                    use_proprio=False,
                    beta_schedule="cosine",
                    diffusion_steps=5,
                    action_samples=64,
                    repeat_last_step=0,
                    learning_rate=3e-4,
                    warmup_steps=2000,
                    actor_decay_steps=int(3e6),
                    image_observations=False,
                    discount=0.99,
                ),
                improve_ddpm_actions_with_global_search=False,
            )
        ),
        "gaussian_diffusion_cql": ml_collections.ConfigDict(
            dict(
                agent="diffusion_cql",
                batch_size=256,
                save_dir=tf.io.gfile.join(SAVE_DIR_PREFIX, "results"),
                seed=0,
                eval_interval=50,
                validation_interval=100,
                save_interval=250,
                log_interval=10,
                deterministic_eval=False,
                num_eval_episodes=50,
                num_episodes_per_video=5,
                num_episodes_per_row=5,
                save_video=False,
                agent_kwargs=get_continuous_cql_config(
                    updates=dict(
                        policy_kwargs=dict(
                            tanh_squash_distribution=True,
                            std_parameterization="uniform",
                        ),
                        discount=0.99,
                        batch_size=256,
                        distributional_critic=True,
                        distributional_critic_kwargs=dict(
                            q_min=-100.0,
                            q_max=0.0,
                            num_bins=128,
                        ),
                        critic_network_type="mlp",
                        critic_kwargs=dict(
                            kernel_init_type="orthogonal",
                            kernel_init_params=dict(
                                scale=1e-2,
                            ),
                        ),
                        critic_network_kwargs=dict(
                            hidden_dims=(256, 256),
                            activate_final=True,
                            kernel_scale_final=1e-2,
                            use_feature_normalization=False,
                            use_layer_norm=True,
                        ),
                        policy_network_kwargs={
                            "hidden_dims": [256, 256],
                            "activate_final": True,
                            "use_layer_norm": False,
                            "use_group_norm": False,
                            "kernel_scale_final": 1e-2,
                        },
                        actor_optimizer_kwargs=dict(
                            learning_rate=1e-4,
                            warmup_steps=0,
                        ),
                        critic_optimizer_kwargs={
                            "learning_rate": 3e-4,
                            "warmup_steps": 0,
                            "weight_decay": 0.0,
                        },
                        temperature_optimizer_kwargs={
                            "learning_rate": 1e-4,
                        },
                        cql_importance_sample=False,
                        cql_n_actions=10,
                        num_ddpm_actions=32,
                        num_actions_to_keep_for_q_diffusion=10,
                        q_diffusion_num_steps=10,
                        q_diffusion_num_steps_for_cql=-1,  # use q_diffusion_num_steps
                        q_diffusion_step_size=3e-4,
                        q_diffusion_optimize_critic_ensemble_min=True,
                        q_diffusion_use_adam=False,
                        q_diffusion_adam_kwargs=dict(
                            b1=0.9,
                            b2=0.999,
                            clip_grad_norm=-1.0,
                        ),
                        q_diffusion_half_step_size_on_overshooting=False,
                        q_diffusion_overshooting_factor=0.5,
                        train_gaussian_policy=False,
                        use_gaussian_policy_for_critic_training=False,
                        always_use_argmax_for_q_diffusion=True,
                        use_calql=True,
                        use_calql_on_random_actions=False,
                        autotune_entropy=False,
                        cql_autotune_alpha=False,
                        use_target_critic_for_q_diffusion_steps=False,
                        use_dataset_actions_for_cql_regularization=False,
                        critic_ensemble_size=2,
                        critic_subsample_size=2,
                        policy_optimizes_ensemble_mean=False,
                        drq_padding=0,
                    ),
                ),
                image_observations=False,
                goal_conditioned=False,
                bound_q_targets=False,
                improve_ddpm_actions_with_global_search=False,
                ddpm_agent_path="",
                ddpm_agent_kwargs=dict(
                    discount=0.99,
                    network_kwargs=dict(
                        hidden_dims=(256, 256, 256),
                        dropout_rate=0.1,
                    ),
                    policy_kwargs=dict(
                        tanh_squash_distribution=False,
                        std_parameterization="uniform",
                        std_min=1e-6,
                        std_max=2.0,
                    ),
                ),
            )
        ),
        "diffusion_iql": ml_collections.ConfigDict(
            dict(
                agent="diffusion_iql",
                batch_size=256,
                save_dir=tf.io.gfile.join(SAVE_DIR_PREFIX, "results"),
                seed=0,
                eval_interval=50,
                validation_interval=100,
                save_interval=500,
                log_interval=10,
                deterministic_eval=False,
                num_eval_episodes=50,
                num_episodes_per_video=5,
                num_episodes_per_row=5,
                save_video=False,
                agent_kwargs=dict(
                    discount=0.99,
                    expectile=0.7,
                    batch_size=256,
                    distributional_critic=True,
                    distributional_critic_kwargs=dict(
                        q_min=-100.0,
                        q_max=0.0,
                        num_bins=128,
                    ),
                    critic_network_type="mlp",
                    critic_kwargs=dict(
                        kernel_init_type="orthogonal",
                        kernel_init_params=dict(
                            scale=1e-2,
                        ),
                    ),
                    value_fns_network_kwargs=dict(
                        hidden_dims=(256, 256),
                        activate_final=True,
                        kernel_scale_final=1e-2,
                        use_feature_normalization=False,
                        use_layer_norm=False,
                    ),
                    value_critic_optimizer_kwargs={
                        "learning_rate": 3e-4,
                        "warmup_steps": 0,
                        "weight_decay": 0.0,
                    },
                    num_ddpm_actions=32,
                    num_actions_to_keep_for_q_diffusion=10,
                    q_diffusion_num_steps=10,
                    q_diffusion_step_size=3e-4,
                    q_diffusion_optimize_critic_ensemble_min=False,
                    q_diffusion_use_adam=False,
                    q_diffusion_adam_kwargs=dict(
                        b1=0.9,
                        b2=0.999,
                        clip_grad_norm=-1.0,
                    ),
                    q_diffusion_half_step_size_on_overshooting=False,
                    q_diffusion_overshooting_factor=0.5,
                    use_target_critic_for_q_diffusion_steps=False,
                    critic_ensemble_size=2,
                    critic_subsample_size=2,
                    drq_padding=0,
                ),
                image_observations=False,
                goal_conditioned=False,
                bound_q_targets=False,
                improve_ddpm_actions_with_global_search=False,
                ddpm_agent_path="",
                ddpm_agent_kwargs=dict(
                    batch_size=256,
                    score_network_kwargs=dict(
                        time_dim=128,
                        num_blocks=3,
                        dropout_rate=0.1,
                        hidden_dim=256,
                        use_layer_norm=True,
                    ),
                    use_proprio=False,
                    beta_schedule="cosine",
                    diffusion_steps=5,
                    action_samples=64,
                    repeat_last_step=0,
                    learning_rate=3e-4,
                    warmup_steps=2000,
                    actor_decay_steps=int(3e6),
                    image_observations=False,
                ),
            )
        ),
        "auto_regressive_transformer": ml_collections.ConfigDict(
            dict(
                agent="auto_regressive_transformer",
                batch_size=256,
                save_dir=tf.io.gfile.join(SAVE_DIR_PREFIX, "results"),
                seed=0,
                eval_interval=500,
                validation_interval=100,
                save_interval=1000,
                log_interval=10,
                deterministic_eval=False,
                num_eval_episodes=50,
                num_episodes_per_video=5,
                num_episodes_per_row=5,
                save_video=False,
                image_observations=False,
                goal_conditioned=False,
                agent_kwargs=dict(
                    learning_rate=1e-4,
                    warmup_steps=2000,
                    image_observations=False,
                    discount=0.99,
                ),
                improve_ddpm_actions_with_global_search=False,
            )
        ),
        "transformer_parl": ml_collections.ConfigDict(
            dict(
                agent="diffusion_cql",
                batch_size=256,
                save_dir=tf.io.gfile.join(SAVE_DIR_PREFIX, "results"),
                seed=0,
                eval_interval=100,
                validation_interval=100,
                save_interval=500,
                log_interval=10,
                deterministic_eval=False,
                num_eval_episodes=50,
                num_episodes_per_video=5,
                num_episodes_per_row=5,
                save_video=False,
                agent_kwargs=get_continuous_cql_config(
                    updates=dict(
                        discount=0.99,
                        batch_size=256,
                        distributional_critic=True,
                        distributional_critic_kwargs=dict(
                            q_min=-400.0,
                            q_max=0.0,
                            num_bins=128,
                        ),
                        critic_network_type="mlp",
                        critic_kwargs=dict(
                            kernel_init_type="orthogonal",
                            kernel_init_params=dict(
                                scale=1e-2,
                            ),
                        ),
                        critic_network_kwargs=dict(
                            hidden_dims=(512, 512, 512),
                            activate_final=True,
                            kernel_scale_final=1e-2,
                            use_feature_normalization=False,
                            use_layer_norm=True,
                        ),
                        critic_optimizer_kwargs={
                            "learning_rate": 3e-4,
                            "warmup_steps": 0,
                            "weight_decay": 0.0,
                        },
                        temperature_optimizer_kwargs={
                            "learning_rate": 1e-4,
                        },
                        cql_importance_sample=False,
                        cql_n_actions=10,
                        num_ddpm_actions=32,
                        num_actions_to_keep_for_q_diffusion=10,
                        q_diffusion_num_steps=10,
                        q_diffusion_num_steps_for_cql=-1,  # use q_diffusion_num_steps
                        q_diffusion_step_size=3e-4,
                        q_diffusion_optimize_critic_ensemble_min=True,
                        q_diffusion_use_adam=False,
                        q_diffusion_adam_kwargs=dict(
                            b1=0.9,
                            b2=0.999,
                            clip_grad_norm=-1.0,
                        ),
                        q_diffusion_half_step_size_on_overshooting=False,
                        q_diffusion_overshooting_factor=0.5,
                        train_gaussian_policy=False,
                        use_gaussian_policy_for_critic_training=False,
                        always_use_argmax_for_q_diffusion=True,
                        use_calql=True,
                        use_calql_on_random_actions=False,
                        autotune_entropy=False,
                        cql_autotune_alpha=False,
                        use_target_critic_for_q_diffusion_steps=False,
                        use_dataset_actions_for_cql_regularization=False,
                        critic_ensemble_size=2,
                        critic_subsample_size=2,
                        policy_optimizes_ensemble_mean=False,
                        drq_padding=0,
                    ),
                ),
                image_observations=False,
                goal_conditioned=False,
                bound_q_targets=False,
                improve_ddpm_actions_with_global_search=False,
                ddpm_agent_path="",
                ddpm_agent_kwargs=dict(
                    learning_rate=3e-5,
                    warmup_steps=2000,
                    image_observations=False,
                    discount=0.99,
                ),
            )
        ),
        "cem_parl": ml_collections.ConfigDict(
            dict(
                agent="diffusion_cql",
                batch_size=256,
                save_dir=tf.io.gfile.join(SAVE_DIR_PREFIX, "results"),
                seed=0,
                eval_interval=100,
                validation_interval=100,
                save_interval=500,
                log_interval=10,
                deterministic_eval=False,
                num_eval_episodes=50,
                num_episodes_per_video=5,
                num_episodes_per_row=5,
                save_video=False,
                agent_kwargs=get_continuous_cql_config(
                    updates=dict(
                        discount=0.99,
                        batch_size=256,
                        distributional_critic=True,
                        distributional_critic_kwargs=dict(
                            q_min=-400.0,
                            q_max=0.0,
                            num_bins=128,
                        ),
                        critic_network_type="mlp",
                        critic_kwargs=dict(
                            kernel_init_type="orthogonal",
                            kernel_init_params=dict(
                                scale=1e-2,
                            ),
                        ),
                        critic_network_kwargs=dict(
                            hidden_dims=(512, 512, 512),
                            activate_final=True,
                            kernel_scale_final=1e-2,
                            use_feature_normalization=False,
                            use_layer_norm=True,
                        ),
                        critic_optimizer_kwargs={
                            "learning_rate": 3e-4,
                            "warmup_steps": 0,
                            "weight_decay": 0.0,
                        },
                        temperature_optimizer_kwargs={
                            "learning_rate": 1e-4,
                        },
                        cql_importance_sample=False,
                        cql_n_actions=10,
                        num_ddpm_actions=1,
                        num_actions_to_keep_for_q_diffusion=1,
                        q_diffusion_num_steps=0,
                        q_diffusion_num_steps_for_cql=-1,  # use q_diffusion_num_steps
                        q_diffusion_step_size=0,
                        q_diffusion_optimize_critic_ensemble_min=True,
                        q_diffusion_use_adam=False,
                        q_diffusion_adam_kwargs=dict(
                            b1=0.9,
                            b2=0.999,
                            clip_grad_norm=-1.0,
                        ),
                        q_diffusion_half_step_size_on_overshooting=False,
                        q_diffusion_overshooting_factor=0.5,
                        train_gaussian_policy=False,
                        use_gaussian_policy_for_critic_training=False,
                        always_use_argmax_for_q_diffusion=True,
                        use_calql=True,
                        use_calql_on_random_actions=False,
                        autotune_entropy=False,
                        cql_autotune_alpha=False,
                        use_target_critic_for_q_diffusion_steps=False,
                        use_dataset_actions_for_cql_regularization=False,
                        critic_ensemble_size=2,
                        critic_subsample_size=2,
                        policy_optimizes_ensemble_mean=False,
                        drq_padding=0,
                    ),
                ),
                image_observations=False,
                goal_conditioned=False,
                bound_q_targets=False,
                improve_ddpm_actions_with_global_search=False,
                ddpm_agent_path="",
                ddpm_agent_kwargs=dict(
                    num_iterations=2,
                    ddpm_checkpoint_path="",
                    ddpm_agent_kwargs=dict(
                        batch_size=256,
                        score_network_kwargs=dict(
                            time_dim=128,
                            num_blocks=3,
                            dropout_rate=0.1,
                            hidden_dim=256,
                            use_layer_norm=True,
                        ),
                        use_proprio=False,
                        beta_schedule="cosine",
                        diffusion_steps=5,
                        action_samples=64,
                        repeat_last_step=0,
                        image_observations=False,
                    ),
                ),
            )
        ),
    }

    return possible_structures[config_string]
